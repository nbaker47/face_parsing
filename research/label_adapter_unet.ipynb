{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label adapter FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 21:06:10.607192: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-17 21:06:10.940951: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-02-17 21:06:12.213213: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nathan/miniconda3/lib/python3.9/site-packages/cv2/../../lib64::/home/nathan/miniconda3/lib/:/home/nathan/miniconda3/lib/:/home/nathan/miniconda3/lib/\n",
      "2023-02-17 21:06:12.213465: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nathan/miniconda3/lib/python3.9/site-packages/cv2/../../lib64::/home/nathan/miniconda3/lib/:/home/nathan/miniconda3/lib/:/home/nathan/miniconda3/lib/\n",
      "2023-02-17 21:06:12.213482: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as F\n",
    "import albumentations as albu\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch import utils\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import label_test_script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparamters\n",
    "ENCODER = 'resnet101'\n",
    "ENCODER_WEIGHTS = 'imagenet' #pretrained weighting\n",
    "ACTIVATION = \"sigmoid\" # softmax2d for multiclass segmentation\n",
    "num_classes = 11\n",
    "\n",
    "mobile = smp.Unet(\n",
    "    in_channels=3,\n",
    "    encoder_name=\"mobilenet_v2\", \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    classes=num_classes, \n",
    "    activation=ACTIVATION,\n",
    "    decoder_use_batchnorm = True,\n",
    ")\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "U2HCK0AnF6pz"
   },
   "outputs": [],
   "source": [
    "def get_training_augmentation():\n",
    "    train_transform = [\n",
    "        albu.Rotate((-11,11),p=0.5),\n",
    "        albu.PadIfNeeded(min_height=128, min_width=128, always_apply=True, border_mode=0),\n",
    "        albu.Perspective(p=0.4),\n",
    "    ]\n",
    "\n",
    "    return albu.Compose(train_transform)\n",
    "\n",
    "\n",
    "def transformation_augs():\n",
    "    train_transform = [\n",
    "    ]\n",
    "    return albu.Compose(train_transform)\n",
    "\n",
    "\n",
    "def get_validation_augmentation():\n",
    "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
    "    test_transform = [\n",
    "        albu.PadIfNeeded(128, 128)\n",
    "    ]\n",
    "    return albu.Compose(test_transform)\n",
    "\n",
    "class MyDataSet(torch.utils.data.Dataset):\n",
    "\n",
    "  def __init__(self, images_dir, masks_dir, coords_dir, preprocessing=None, classes=None,augmentation=None, training=True):\n",
    "    super(MyDataSet, self).__init__()\n",
    "    \n",
    "    self.preprocessing = preprocessing\n",
    "    self.augmentation = augmentation\n",
    "\n",
    "    self.image_ids = os.listdir(images_dir)\n",
    "\n",
    "    train_slice = int(len(self.image_ids)*0.2)\n",
    "\n",
    "    if training == True:\n",
    "      self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.image_ids][train_slice::]\n",
    "      self.masks_fps = [os.path.join(masks_dir, mask_id) for mask_id in self.image_ids][train_slice::]\n",
    "    else:\n",
    "      self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.image_ids][:train_slice]\n",
    "      self.masks_fps = [os.path.join(masks_dir, mask_id) for mask_id in self.image_ids][:train_slice]\n",
    "\n",
    "  def __len__(self):\n",
    "    # a DataSet must know it size\n",
    "    return len(self.images_fps)\n",
    "\n",
    "  def __getitem__(self, i):\n",
    "\n",
    "    image = cv2.imread(self.images_fps[i], 0)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    mask = cv2.imread(self.masks_fps[i], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    sample = self.augmentation(image=image, mask=mask)\n",
    "    image, mask = sample['image'], sample['mask']\n",
    "\n",
    "    image = torch.tensor(image)\n",
    "\n",
    "    #onehot\n",
    "    one_hot_Y = torch.nn.functional.one_hot(torch.tensor(mask).to(torch.int64), 11).float()\n",
    "\n",
    "    return (image.permute(2,0,1).float(), one_hot_Y.permute(2,0,1).float())\n",
    "\n",
    "\n",
    "train_x_path = \"/home/nathan/Documents/final_project/datasets/label_adapter_helen_train/images\"\n",
    "train_y_path = \"/home/nathan/Documents/final_project/datasets/label_adapter_helen_train/masks\"\n",
    "\n",
    "val_x_path = train_x_path\n",
    "val_y_path = train_y_path\n",
    "\n",
    "train_ds2 = MyDataSet(train_x_path, train_y_path, None, augmentation=get_training_augmentation())\n",
    "val_ds2 = MyDataSet(val_x_path, val_y_path, None, training=False, augmentation=get_validation_augmentation())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lXVQ-_zZF6p1"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Get train and val data loaders\n",
    "train_loader2 = DataLoader(train_ds2, batch_size=24, shuffle=True, num_workers=7)\n",
    "valid_loader2 = DataLoader(val_ds2, batch_size=24, shuffle=False, num_workers=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set flag to train the model or not. If set to 'False', only prediction is performed (using an older model checkpoint)\n",
    "TRAINING = True\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loss = smp.utils.losses.CrossEntropyLoss()\n",
    "\n",
    "# define evalusation metrics\n",
    "metrics = [\n",
    "    smp.utils.metrics.IoU(threshold=0.5),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader_given, valid_loader_given, saveas, epoch):\n",
    "\n",
    "    #clear CUDA cache\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # define optimizer\n",
    "    optimizer = torch.optim.NAdam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # define learning rate scheduler\n",
    "    #lr_scheduler = torch.optim.lr_scheduler.PolynomialLR(optimizer)\n",
    "\n",
    "    #define train ecpochs w/ our hyperparams\n",
    "    train_epoch = smp.utils.train.TrainEpoch(\n",
    "        model, \n",
    "        loss=loss, \n",
    "        metrics=metrics, \n",
    "        optimizer=optimizer,\n",
    "        device=DEVICE,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    #define train ecpochs w/ our hyperparams\n",
    "    valid_epoch = smp.utils.train.ValidEpoch(\n",
    "        model, \n",
    "        loss=loss, \n",
    "        metrics=metrics, \n",
    "        device=DEVICE,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    if TRAINING:\n",
    "\n",
    "        best_iou_score = 0.0\n",
    "        train_logs_list, valid_logs_list = [], []\n",
    "\n",
    "        #Keep track of epoch BCE and IoU for graph plots\n",
    "        epoch_count = []\n",
    "        v_bce = []\n",
    "        v_ious = []\n",
    "\n",
    "        t_bce = []\n",
    "        t_ious = []\n",
    "\n",
    "        i = 0\n",
    "        while i < epoch:\n",
    "            i +=1 \n",
    "\n",
    "            # Perform training & validation\n",
    "            print('\\nEpoch: {}'.format(i))\n",
    "            train_logs = train_epoch.run(train_loader_given)\n",
    "            valid_logs = valid_epoch.run(valid_loader_given)\n",
    "            #lr_scheduler.step()\n",
    "\n",
    "            #log\n",
    "            train_logs_list.append(train_logs)\n",
    "            valid_logs_list.append(valid_logs)\n",
    "\n",
    "            # Save model if a better val IoU score is obtained\n",
    "            if best_iou_score < valid_logs['iou_score']:\n",
    "                best_iou_score = valid_logs['iou_score']\n",
    "                torch.save(model, saveas)\n",
    "                print('Model saved!')\n",
    "\n",
    "            v_ious.append(valid_logs['iou_score'])\n",
    "            t_ious.append(train_logs['iou_score'])\n",
    "            \n",
    "            epoch_count.append(i)\n",
    "        \n",
    "            # Plot graph every 2 epochs\n",
    "            if i % 2 ==0:\n",
    "                plt.show()\n",
    "                plt.plot(epoch_count,t_ious, label=\"Train IoU\")\n",
    "                plt.plot(epoch_count,v_ious, label=\"Valid IoU\")\n",
    "                plt.legend(loc=\"upper left\")\n",
    "                plt.xlabel(\"Epochs\")\n",
    "                plt.ylabel(\"IoU\")\n",
    "                plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_model(mobile, train_loader2, valid_loader2, \"/home/nathan/Documents/final_project/saved_models/label_adapted_helen.pth\", 50)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "01070a215043f07a8263edac27ed84a056fb8ad0ef2223506d9cf2bf6f4d5c3c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
